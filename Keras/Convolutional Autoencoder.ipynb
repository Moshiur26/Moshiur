{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense,Input,Conv2D,MaxPooling2D,UpSampling2D,Flatten,Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "#download mnist data and split into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#X_train[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_value=float(X_train.max())\n",
    "X_train=X_train.astype('float32')/max_value\n",
    "X_test=X_test.astype('float32')/max_value\n",
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=X_train.reshape(len(X_train),28,28,1)\n",
    "X_test=X_test.reshape(len(X_test),28,28,1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=X_train.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder=Sequential()\n",
    "#Encoder Layers\n",
    "autoencoder.add(Conv2D(16,(3,3),activation='relu',padding='same',input_shape=X_train.shape[1:]))\n",
    "autoencoder.add(MaxPooling2D((2,2),padding='same'))\n",
    "autoencoder.add(Conv2D(8,(3,3),activation='relu',padding='same'))\n",
    "autoencoder.add(MaxPooling2D((2,2),padding='same'))\n",
    "autoencoder.add(Conv2D(8,(3,3),strides=(2,2),activation='relu',padding='same'))\n",
    "\n",
    "#Flateen encoding for visualization\n",
    "autoencoder.add(Flatten())\n",
    "autoencoder.add(Reshape((4,4,8)))\n",
    "\n",
    "#Decoder Layers\n",
    "autoencoder.add(Conv2D(8,(3,3),activation='relu',padding='same'))\n",
    "autoencoder.add(UpSampling2D((2,2)))\n",
    "autoencoder.add(Conv2D(8,(3,3),activation='relu',padding='same'))\n",
    "autoencoder.add(UpSampling2D((2,2)))\n",
    "autoencoder.add(Conv2D(16,(3,3),activation='relu'))\n",
    "autoencoder.add(UpSampling2D((2,2)))\n",
    "autoencoder.add(Conv2D(1,(3,3),activation='sigmoid',padding='same'))\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7_input (InputLayer)  (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 1,904\n",
      "Trainable params: 1,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder=Model(inputs=autoencoder.input,outputs=autoencoder.get_layer('flatten_3').output)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 154s 3ms/step - loss: 0.2708 - val_loss: 0.1602\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 176s 3ms/step - loss: 0.1460 - val_loss: 0.1338\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.1287 - val_loss: 0.1223\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 149s 2ms/step - loss: 0.1201 - val_loss: 0.1165\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 149s 2ms/step - loss: 0.1147 - val_loss: 0.1116\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.1109 - val_loss: 0.1085\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.1084 - val_loss: 0.1060\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.1063 - val_loss: 0.1041\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.1046 - val_loss: 0.1026\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.1029 - val_loss: 0.1012\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.1014 - val_loss: 0.0996\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.1002 - val_loss: 0.0987\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0990 - val_loss: 0.0973\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.0980 - val_loss: 0.0964\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0971 - val_loss: 0.0955\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0964 - val_loss: 0.0947\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.0955 - val_loss: 0.0940\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0949 - val_loss: 0.0934\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0943 - val_loss: 0.0928\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0938 - val_loss: 0.0923\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 150s 2ms/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 157s 3ms/step - loss: 0.0929 - val_loss: 0.0915\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.0924 - val_loss: 0.0911\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0921 - val_loss: 0.0908\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0918 - val_loss: 0.0907\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.0914 - val_loss: 0.0901\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 149s 2ms/step - loss: 0.0911 - val_loss: 0.0905\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0908 - val_loss: 0.0906\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.0906 - val_loss: 0.0893\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.0903 - val_loss: 0.0892\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0901 - val_loss: 0.0889\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0899 - val_loss: 0.0888\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.0896 - val_loss: 0.0885\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.0894 - val_loss: 0.0881\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.0892 - val_loss: 0.0881\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.0890 - val_loss: 0.0877\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.0888 - val_loss: 0.0882\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 149s 2ms/step - loss: 0.0886 - val_loss: 0.0874\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.0885 - val_loss: 0.0879\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0883 - val_loss: 0.0872\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.0881 - val_loss: 0.0869\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.0880 - val_loss: 0.0867\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 148s 2ms/step - loss: 0.0878 - val_loss: 0.0867\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 152s 3ms/step - loss: 0.0877 - val_loss: 0.0864\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 157s 3ms/step - loss: 0.0875 - val_loss: 0.0863\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0874 - val_loss: 0.0861\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.0873 - val_loss: 0.0860\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 169s 3ms/step - loss: 0.0872 - val_loss: 0.0865\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0870 - val_loss: 0.0858\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 163s 3ms/step - loss: 0.0869 - val_loss: 0.0856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28664cc1c88>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam',loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train,X_train,epochs=50,batch_size=256,shuffle=True,validation_data=(X_test,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
